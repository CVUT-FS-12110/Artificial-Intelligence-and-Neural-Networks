{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf8bd9d",
   "metadata": {},
   "source": [
    "\n",
    "# K-Means Clustering Tutorial\n",
    "\n",
    "## Introduction\n",
    "K-means clustering is a popular unsupervised machine learning algorithm. It's used for grouping data into clusters based on feature similarity. The 'K' in k-means represents the number of clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ccd768",
   "metadata": {},
   "source": [
    "\n",
    "## Algorithm Explanation\n",
    "The k-means algorithm partitions a set of \\( N \\) data points into \\( K \\) clusters. Each point belongs to the cluster with the nearest mean. The algorithm involves the following steps:\n",
    "\n",
    "1. **Initialization**: Choose \\( K \\) initial centroids (cluster centers).\n",
    "2. **Assignment**: Assign each data point to the nearest centroid.\n",
    "3. **Update**: Recompute the centroids as the mean of all points in the cluster.\n",
    "4. **Repeat**: Repeat steps 2 and 3 until convergence (when assignments no longer change).\n",
    "\n",
    "![Alt text](kmeans_iterations.gif)\n",
    "\n",
    "### Mathematical Background.\n",
    "\n",
    "## Objective\n",
    "\n",
    "- The goal is to divide $M$ data points into $k$ clusters.\n",
    "- Minimize the within-cluster sum of squares (WCSS).\n",
    "\n",
    "## Notation\n",
    "\n",
    "- $X = \\{x_1, x_2, \\ldots, x_M\\}$: Set of data points.\n",
    "- $C = \\{c_1, c_2, \\ldots, c_k\\}$: Set of centroids for the clusters.\n",
    "\n",
    "## Algorithm Steps\n",
    "\n",
    "1. **Initialization**: \n",
    "   - Select $k$ initial centroids randomly or using a heuristic.\n",
    "\n",
    "2. **Assignment Step**: \n",
    "   - Assign each data point $x_i$ to the nearest centroid.\n",
    "   - $S(i) = \\text{argmin}_j \\|x_i - c_j\\|^2$\n",
    "   - $S(i)$ is the index of the nearest centroid to $x_i$.\n",
    "\n",
    "3. **Update Step**: \n",
    "   - Update the centroids to the mean of all points assigned to them.\n",
    "   - $c_j = \\frac{1}{|S_j|} \\sum_{x_i \\in S_j} x_i$\n",
    "   - $S_j$ is the set of points assigned to centroid $c_j$.\n",
    "\n",
    "4. **Iterate**:\n",
    "   - Repeat until centroids stabilize or a max number of iterations is reached.\n",
    "   - WCSS: $\\sum_{j=1}^{k} \\sum_{x\n",
    "with different shapes, sizes, or high-dimensional data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed9d8c-6c38-4d45-8df5-9c3f0844ea47",
   "metadata": {},
   "source": [
    "## Convergence\n",
    "\n",
    "- The algorithm converges but may reach a local minimum.\n",
    "- The initial selection of centroids is crucial.\n",
    "- Often run multiple times for better solutions .\n",
    "\n",
    "## Complexity\n",
    "\n",
    "- Generally, $O(n \\cdot k \\cdot d \\cdot i)$, where:\n",
    "  - $n$ is the number of data points,\n",
    "  - $k$ is the number of clusters,\n",
    "  - $d$ is the dimensionality of data,\n",
    "  - $i$ is the number of iterations.\n",
    "\n",
    "## Considerations\n",
    "\n",
    "- **Choosing $k$**: Critical and not determined by the algorithm.\n",
    "- **Scaling**: Often necessary to scale data before applying k-means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa1e39-43ed-4be5-b574-dfd19210f1d1",
   "metadata": {},
   "source": [
    "## Variants\n",
    "\n",
    "- **k-means++**: Offers smarter initialization of centroids.\n",
    "\n",
    "K-means is effective for spherical clusters but can struggle with different shapes, sizes, or high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07212b1",
   "metadata": {},
   "source": [
    "\n",
    "## Implementation from Scratch\n",
    "Let's implement the k-means algorithm in Python from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ba468-0858-4729-a5b2-434e6e0bcccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])  # Shape (2, 3)\n",
    "b = np.array([1, 2, 3])               # Shape (3,)\n",
    "c =  b[np.newaxis, :]\n",
    "# Reshape 'b' and broadcast it with 'A'\n",
    "result = A + b[np.newaxis, :]  # 'b' is reshaped to (1, 3)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def kmeans(X, K, max_iters=100):\n",
    "    # Step 1: Initialize centroids randomly\n",
    "    centroids = X[np.random.choice(X.shape[0], K, replace=False)]\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Step 2: Assign points to the nearest centroid\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        closest_centroid = np.argmin(distances, axis=0)\n",
    "\n",
    "        # Step 3: Update centroids\n",
    "        new_centroids = np.array([X[closest_centroid == k].mean(axis=0) for k in range(K)])\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return closest_centroid, centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820948a0",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset Generation\n",
    "We'll generate a synthetic dataset to apply our k-means implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.concatenate([np.random.randn(150, 2) * 0.75 + np.array([2, 2]),\n",
    "                    np.random.randn(100, 2) * 0.5 - np.array([2, 2]),\n",
    "                    np.random.randn(100, 2) * 0.5 + np.array([-2, -3])])\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.title('Synthetic Dataset')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d0967",
   "metadata": {},
   "source": [
    "\n",
    "## Visualization\n",
    "We'll visualize the results of our k-means clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcef6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply k-means\n",
    "K = 3\n",
    "labels, centroids = kmeans(X, K)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], s=100, c='red') # Centroids\n",
    "plt.title('K-Means Clustering Results')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a753d",
   "metadata": {},
   "source": [
    "\n",
    "## Elbow Method\n",
    "The elbow method helps to determine the optimal number of clusters. We plot the variance against the number of clusters and look for an 'elbow' where the rate of decrease sharply changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0950b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_inertia(X, centroids, labels):\n",
    "    inertia = 0\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        inertia += ((X[labels == i] - centroid) ** 2).sum()\n",
    "    return inertia\n",
    "\n",
    "inertias = []\n",
    "for k in range(1, 10):\n",
    "    labels, centroids = kmeans(X, k)\n",
    "    inertia = compute_inertia(X, centroids, labels)\n",
    "    inertias.append(inertia)\n",
    "\n",
    "plt.plot(range(1, 10), inertias, 'bo-')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f670c2",
   "metadata": {},
   "source": [
    "\n",
    "## Automatic Cluster Number Selection\n",
    "We'll use the differences in the elbow graph to automatically select the number of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92691952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the differences in inertia\n",
    "diffs = np.diff(inertias)\n",
    "# Find the elbow point\n",
    "optimal_k = np.argmin(diffs[diffs > 0]) + 2\n",
    "\n",
    "plt.plot(range(1, 10), inertias, 'bo-')\n",
    "plt.axvline(x=optimal_k, color='r', linestyle='--')\n",
    "plt.title('Optimal Number of Clusters: {}'.format(optimal_k))\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39472b8",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "This tutorial demonstrated how to implement and apply k-means clustering from scratch. The elbow method, along with an automatic approach to select the number of clusters, provides a practical way to apply k-means in various scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb361b1",
   "metadata": {},
   "source": [
    "\n",
    "## Limitations of K-Means: Non-Convex Shapes\n",
    "K-means works well with globular (spherical) cluster shapes. However, it struggles with non-convex shapes like half-moons due to its reliance on Euclidean distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a288533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Generate half-moons data\n",
    "X_moons, y_moons = make_moons(n_samples=300, noise=0.05, random_state=42)\n",
    "\n",
    "# Visualize the data\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1])\n",
    "plt.title('Half-Moons Dataset')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dccc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply k-means to half-moons dataset\n",
    "labels_moons, _ = kmeans(X_moons, K=2)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=labels_moons, cmap='viridis')\n",
    "plt.title('K-Means on Half-Moons')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ca242",
   "metadata": {},
   "source": [
    "\n",
    "As seen in the visualization, k-means is unable to accurately capture the structure of the half-moons dataset. This limitation highlights the importance of understanding the data distribution and the characteristics of the chosen clustering algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DBScan - (Density-Based Spatial Clustering of Applications with Noise)\n",
    "groups data points based on their density, identifying clusters of high-density regions and classifying outliers as noise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=3) # eps - maximal distance between two points in cluster, min_samples - minimal number of points in cluster\n",
    "labels_moons_db = dbscan.fit_predict(X=X_moons)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=labels_moons_db, cmap='viridis')\n",
    "plt.title('DBScan on Half-Moons')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "e4af5da8-20a2-4100-b443-0554f380a38c",
   "metadata": {},
   "source": [
    "### Code for animated gif generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ce411-f6c5-403f-95bf-9bb193c532c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "\n",
    "def kmeans(X, K, max_iters=10):\n",
    "    centroids = X[np.random.choice(X.shape[0], K, replace=False)]\n",
    "    history_centroids = [centroids]\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        closest_centroid = np.argmin(distances, axis=0)\n",
    "        centroids = np.array([X[closest_centroid == k].mean(axis=0) for k in range(K)])\n",
    "        history_centroids.append(centroids)\n",
    "    \n",
    "    return closest_centroid, centroids, history_centroids\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.concatenate([np.random.randn(150, 2) * 0.75 + np.array([2, 2]),\n",
    "                    np.random.randn(100, 2) * 0.5 - np.array([2, 2]),\n",
    "                    np.random.randn(100, 2) * 0.5 + np.array([-2, -3])])\n",
    "\n",
    "# Apply k-means\n",
    "K = 3\n",
    "labels, final_centroids, history_centroids = kmeans(X, K)\n",
    "\n",
    "# Animation\n",
    "fig, ax = plt.subplots()\n",
    "colors = ['blue', 'green', 'orange']\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    centroids = history_centroids[frame]\n",
    "    for i in range(K):\n",
    "        points = X[labels == i]\n",
    "        ax.scatter(points[:, 0], points[:, 1], s=50, color=colors[i])\n",
    "        ax.scatter(centroids[i, 0], centroids[i, 1], s=100, color='red')\n",
    "    ax.set_title(f'Iteration {frame + 1}')\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(history_centroids), interval=1000, repeat=False)\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = 'kmeans_iterations.gif'\n",
    "ani.save(gif_path, writer='pillow')\n",
    "Image(filename=gif_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c52c5-edfc-4848-83e5-7b30d0f2cf05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31815620-f84a-44ca-96d3-ecea301f035b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
