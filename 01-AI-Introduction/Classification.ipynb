{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cef193a-1f6c-4ab8-a8a0-c1f38ccc14a7",
   "metadata": {},
   "source": [
    "# Classification\n",
    "The task is to identify which category an object belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c303c-f741-48c5-aaf5-97671d91687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ccc1f-9e12-4e15-9c94-38285f538294",
   "metadata": {},
   "source": [
    "### Let's try to create an ML model for recognizing handwritten numbers. We download the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f99f7-72e2-4356-9a8f-bbcc67fcc88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f07ab0-1892-4966-a105-88febf3a6dfa",
   "metadata": {},
   "source": [
    "### Now we can see what our task is. From the small greyscale pictures, decide what number is written on it. The correct answer is marked here as `target`. Since we know the correct answer, we can used some method based on the supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8380697-9531-4f7c-b792-54a54dd5d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for idx in range(25):\n",
    "    plt.subplot(5, 5, idx+1)\n",
    "    fig = plt.imshow(x_train[idx], cmap='gray')\n",
    "    plt.title('Target {}'.format(y_train[idx]))\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1802b16-feed-4e20-baf2-b08d5dfca032",
   "metadata": {},
   "source": [
    "### We will use the Neural Network. First we create a simple neural network a model, here using the Tensorflow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787ecb3-4bb6-45ac-89d4-202b85b78ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(256),\n",
    "                                    tf.keras.layers.Dropout(0.25),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314014c-252b-4f31-aa20-4f24e995b78b",
   "metadata": {},
   "source": [
    "### We now train the created model on the training data and then evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b633f74-b2aa-4e49-bb19-8c1b4a9ecd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=512, shuffle=True)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36015b-5c21-4d25-aae8-fd083d3911ca",
   "metadata": {},
   "source": [
    "### Now we can see the resulting classification, the caption above the image we are trying to classify is in the format {correct answer} - {prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05908206-4f4a-4640-bd37-60999016c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "start = 100\n",
    "for idx in range(25):\n",
    "    plt.subplot(5,5,idx+1)\n",
    "    fig = plt.imshow(x_test[idx+start], cmap='gray')\n",
    "#     print(model.predict(x_test[idx+start].reshape(1, 28, 28)), np.argmax(model.predict(x_test[idx+start].reshape(1, 28, 28))))\n",
    "    plt.title('{} - {}'.format(y_test[idx+start], np.argmax(model.predict(x_test[idx+start].reshape(1, 28, 28)))))\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66dd0f-b363-4be4-bf59-d7c42c174ea3",
   "metadata": {},
   "source": [
    "### In the figure below we can isnpect a few incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7d078-215d-48ff-a259-f02068feffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict = np.argmax(model.predict(x_test), axis=1)\n",
    "wrong = np.where(ypredict-y_test)[0]\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "start = 100\n",
    "for idx in range(25):\n",
    "    plt.subplot(5,5,idx+1)\n",
    "    fig = plt.imshow(x_test[wrong[idx]], cmap='gray')\n",
    "    plt.title('{} - {}'.format(y_test[wrong[idx]], ypredict[wrong[idx]]))\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d78e1-09c2-46e1-aac0-bf2b08f69d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from textwrap import dedent\n",
    "import base64, io, numpy as np\n",
    "from PIL import Image\n",
    "from google.colab import output\n",
    "import ipywidgets as W\n",
    "import tensorflow as tf\n",
    "\n",
    "display(HTML(dedent(\"\"\"\n",
    "<style>\n",
    "#draw-wrap { display: inline-block; user-select: none; }\n",
    "#draw-toolbar { margin-bottom: 8px; display: flex; gap: 8px; align-items: center; }\n",
    "#draw-canvas { border: 1px solid #ccc; touch-action: none; background: white; }\n",
    "#pred-output { font-family: ui-monospace, monospace; margin-top: 8px; }\n",
    "</style>\n",
    "<div id=\"draw-wrap\">\n",
    "  <div id=\"draw-toolbar\">\n",
    "    <label>Brush size: <input id=\"brush\" type=\"range\" min=\"3\" max=\"40\" step=\"1\" value=\"18\"></label>\n",
    "    <button id=\"eraser\">Eraser</button>\n",
    "    <button id=\"pen\" disabled>Pen</button>\n",
    "    <button id=\"clear\">Clear</button>\n",
    "  </div>\n",
    "  <canvas id=\"draw-canvas\" width=\"280\" height=\"280\"></canvas>\n",
    "  <div id=\"pred-output\">Draw a digit (0–9). Then run the prediction cell.</div>\n",
    "</div>\n",
    "<script>\n",
    "(() => {\n",
    "  const canvas = document.getElementById('draw-canvas');\n",
    "  const ctx = canvas.getContext('2d');\n",
    "  const brush = document.getElementById('brush');\n",
    "  const btnEraser = document.getElementById('eraser');\n",
    "  const btnPen = document.getElementById('pen');\n",
    "  const btnClear = document.getElementById('clear');\n",
    "  const out = document.getElementById('pred-output');\n",
    "\n",
    "  // white background\n",
    "  ctx.fillStyle = 'white';\n",
    "  ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "\n",
    "  let drawing = false;\n",
    "  let last = null;\n",
    "  let erasing = false;\n",
    "\n",
    "  const getPos = (e) => {\n",
    "    const r = canvas.getBoundingClientRect();\n",
    "    if (e.touches && e.touches[0]) {\n",
    "      return { x: e.touches[0].clientX - r.left, y: e.touches[0].clientY - r.top };\n",
    "    }\n",
    "    return { x: e.clientX - r.left, y: e.clientY - r.top };\n",
    "  };\n",
    "\n",
    "  const drawLine = (x0, y0, x1, y1, w) => {\n",
    "    ctx.lineWidth = w;\n",
    "    ctx.lineCap = 'round';\n",
    "    ctx.strokeStyle = erasing ? 'white' : 'black';\n",
    "    ctx.beginPath();\n",
    "    ctx.moveTo(x0, y0);\n",
    "    ctx.lineTo(x1, y1);\n",
    "    ctx.stroke();\n",
    "  };\n",
    "\n",
    "  const start = (e) => { drawing = true; last = getPos(e); e.preventDefault(); };\n",
    "  const move  = (e) => {\n",
    "    if (!drawing) return;\n",
    "    const p = getPos(e);\n",
    "    drawLine(last.x, last.y, p.x, p.y, parseInt(brush.value));\n",
    "    last = p;\n",
    "    e.preventDefault();\n",
    "  };\n",
    "  const end   = (e) => { drawing = false; last = null; e.preventDefault(); };\n",
    "\n",
    "  canvas.addEventListener('mousedown', start);\n",
    "  canvas.addEventListener('mousemove', move);\n",
    "  canvas.addEventListener('mouseup', end);\n",
    "  canvas.addEventListener('mouseleave', end);\n",
    "  canvas.addEventListener('touchstart', start, {passive:false});\n",
    "  canvas.addEventListener('touchmove', move, {passive:false});\n",
    "  canvas.addEventListener('touchend', end);\n",
    "\n",
    "  btnClear.onclick = () => {\n",
    "    ctx.fillStyle = 'white';\n",
    "    ctx.fillRect(0,0,canvas.width, canvas.height);\n",
    "    out.textContent = \"Canvas cleared.\";\n",
    "  };\n",
    "  btnEraser.onclick = () => { erasing = true; btnEraser.disabled = true; btnPen.disabled = false; };\n",
    "  btnPen.onclick = () => { erasing = false; btnPen.disabled = true; btnEraser.disabled = false; };\n",
    "\n",
    "  // functions available to Python via eval_js\n",
    "  window.__mnist_get_png = () => canvas.toDataURL('image/png');\n",
    "  window.__mnist_message = (txt) => { out.textContent = txt; };\n",
    "})();\n",
    "</script>\n",
    "\"\"\")))\n",
    "\n",
    "INVERT = True\n",
    "SIZE = (28, 28)\n",
    "\n",
    "# --- UI elements ---\n",
    "lbl = W.HTML(value=\"Ready.\")\n",
    "btn = W.Button(description=\"Predict\", button_style=\"primary\")\n",
    "stats = W.HTML(value=\"\")\n",
    "img_small = W.HTML()\n",
    "img_large = W.HTML()\n",
    "\n",
    "box_preview = W.VBox([\n",
    "    W.HTML(\"<b>Network input (28×28, grayscale)</b>\"),\n",
    "    W.HBox([img_small, img_large]),\n",
    "    stats\n",
    "])\n",
    "display(W.HBox([btn, lbl]))\n",
    "display(box_preview)\n",
    "\n",
    "def _to_png_bytes(arr_2d_uint8: np.ndarray) -> bytes:\n",
    "    im = Image.fromarray(arr_2d_uint8, mode='L')\n",
    "    bio = io.BytesIO()\n",
    "    im.save(bio, format='PNG')\n",
    "    return bio.getvalue()\n",
    "\n",
    "def preprocess_from_canvas() -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - a2d: float32 (28,28) in [0,1] – for the model\n",
    "      - a8:  uint8 (28,28) in [0,255] – for previews\n",
    "    \"\"\"\n",
    "    data_url = output.eval_js(\"__mnist_get_png()\")\n",
    "    b64 = data_url.split(\",\", 1)[1]\n",
    "    img = Image.open(io.BytesIO(base64.b64decode(b64))).convert(\"RGB\")\n",
    "\n",
    "    arr = np.array(img, dtype=np.float32)       # (H,W,3)\n",
    "    gray = arr.mean(axis=2)                     # (H,W) [0..255]\n",
    "    if INVERT:\n",
    "        gray = 255.0 - gray\n",
    "    im28 = Image.fromarray(gray.astype(np.uint8)).resize(SIZE, Image.LANCZOS)\n",
    "\n",
    "    a8 = np.asarray(im28, dtype=np.uint8)       # (28,28) uint8 [0..255]\n",
    "    a2d = a8.astype(np.float32) / 255.0         # (28,28) float32 [0,1]\n",
    "    return a2d, a8\n",
    "\n",
    "def _normalize_input_shape(shape):\n",
    "    if isinstance(shape, (list, tuple)) and shape and isinstance(shape[0], (list, tuple)):\n",
    "        return shape[0]\n",
    "    return shape\n",
    "\n",
    "def make_batch(a2d: np.ndarray) -> np.ndarray:\n",
    "    insh = _normalize_input_shape(getattr(model, \"input_shape\", None))\n",
    "    if insh is None:\n",
    "        x = a2d[np.newaxis, ...]                            # (1,28,28)\n",
    "    else:\n",
    "        if len(insh) == 3:                                  # (None, H, W)\n",
    "            x = a2d[np.newaxis, ...]                        # (1,28,28)\n",
    "        elif len(insh) == 4:                                # (None, H, W, C)\n",
    "            c = insh[-1] if isinstance(insh[-1], int) else 1\n",
    "            if c == 1:\n",
    "                x = a2d[..., np.newaxis][np.newaxis, ...]   # (1,28,28,1)\n",
    "            else:\n",
    "                x = np.repeat(a2d[..., np.newaxis], c, axis=-1)[np.newaxis, ...]\n",
    "        else:\n",
    "            x = a2d[np.newaxis, ...]\n",
    "    return np.asarray(x, dtype=np.float32)\n",
    "\n",
    "def on_click(_):\n",
    "    try:\n",
    "        a2d, a8 = preprocess_from_canvas()      # (28,28) float32 and (28,28) uint8\n",
    "        png = _to_png_bytes(a8)\n",
    "        b64 = base64.b64encode(png).decode(\"ascii\")\n",
    "\n",
    "        # pixel-perfect previews\n",
    "        img_small.value = f'<img src=\"data:image/png;base64,{b64}\" style=\"width:28px;height:28px;image-rendering: pixelated;border:1px solid #ccc;margin-right:12px;\" />'\n",
    "        img_large.value = f'<img src=\"data:image/png;base64,{b64}\" style=\"width:280px;height:280px;image-rendering: pixelated;border:1px solid #ccc;\" />'\n",
    "\n",
    "        stats.value = (\n",
    "            f\"<tt>array shape: (28,28), dtype=float32, \"\n",
    "            f\"min={a2d.min():.3f}, max={a2d.max():.3f}, mean={a2d.mean():.3f}</tt>\"\n",
    "        )\n",
    "\n",
    "        x = make_batch(a2d)\n",
    "        y = model.predict(x, verbose=0)[0].astype(np.float32)\n",
    "        pred = int(y.argmax())\n",
    "        top3 = y.argsort()[-3:][::-1]\n",
    "        msg = \"Prediction: <b>{}</b> | Top-3: {}\".format(\n",
    "            pred, \", \".join(f\"{i}: {y[i]:.3f}\" for i in top3)\n",
    "        )\n",
    "        lbl.value = msg\n",
    "        output.eval_js(f'__mnist_message(\"{msg}\")')\n",
    "    except Exception as e:\n",
    "        msg = f\"<span style='color:#b00'>Prediction error: {e}</span>\"\n",
    "        lbl.value = msg\n",
    "        s = str(e).replace(\"\\\\\", \"/\").replace('\"', '\\\\\"')\n",
    "        output.eval_js(f'__mnist_message(\"Prediction error: {s}\")')\n",
    "\n",
    "btn.on_click(on_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5cf9d-7419-4ed5-a522-0406c1a44200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
