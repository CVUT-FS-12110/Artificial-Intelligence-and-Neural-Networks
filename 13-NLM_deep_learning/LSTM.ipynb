{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model configuration\n",
    "additional_metrics = ['accuracy']\n",
    "batch_size = 128\n",
    "embedding_output_dims = 15\n",
    "loss_function = BinaryCrossentropy()\n",
    "max_sequence_length = 300\n",
    "num_distinct_words = 5000\n",
    "optimizer = 'adam'\n",
    "validation_split = 0.20\n",
    "verbosity_mode = 1\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_distinct_words)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Pad all sequences\n",
    "padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
    "padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
    "\n",
    "# Define the Keras model\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "\n",
    "# Give a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e70e3-65af-4ab2-bdd2-ef9484ebd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 5\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(padded_inputs, y_train, batch_size=batch_size, epochs=number_of_epochs, verbose=verbosity_mode, validation_split=validation_split)\n",
    "\n",
    "# Test the model after training\n",
    "test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)\n",
    "print('Test results - Loss: {} - Accuracy: {}%'.format(test_results[0], 100*test_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(padded_inputs_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82305b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    print(y_test[idx], predict[idx])\n",
    "    print(\" \".join(str(padded_inputs_test[idx])))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default parameters to keras.datasets.imdb.load_data\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "\n",
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "# And add `index_from` to indices to sync with `x_train`\n",
    "inverted_word_index = dict(\n",
    "    (i + index_from, word) for (word, i) in word_index.items()\n",
    ")\n",
    "\n",
    "# Update `inverted_word_index` to include `start_char` and `oov_char`\n",
    "inverted_word_index[start_char] = \"[START]\"\n",
    "inverted_word_index[oov_char] = \"[OOV]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    print(y_test[idx], predict[idx])\n",
    "    print(\" \".join(inverted_word_index[i] for i in padded_inputs_test[idx] if i > 0))\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
